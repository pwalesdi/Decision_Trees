{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to build Decision Trees\n",
    "Authors: Patrick Wales-Dinan\n",
    "\n",
    "<img src=\"./images/new_job.png\" align=\"left\" width=1000>\n",
    "\n",
    "- (This image is courtesy of [Rajesh Brid](https://medium.com/@rajesh_brid).)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Objectives\n",
    "\n",
    "- Understand what a decision tree is.\n",
    "- Calculate Gini Impurity.\n",
    "- Describe how decision trees use Gini Impurity to make decisions.\n",
    "- Fit, generate predictions from, and evaluate decision tree models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What should we do today?\n",
    "\n",
    "|$Y = $ Activity|$X_1 = $ Day|$X_2 = $ Weather|\n",
    "|:---------:|:--------------:|:----------:|\n",
    "|   Movies  |      Weekend     |   Rainy  |\n",
    "|   Netflix |      Weekday     |   Sunny  |\n",
    "|   Beach   |      Weekend     |   Sunny  |\n",
    "|   Netflix |      Weekday     |   Rainy  |\n",
    "|   Netflix |      Weekday     |   Rainy  |\n",
    "|   Beach   |      Weekend     |   Sunny  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>It's a weekday. Based on our past behavior, what do you think we'll do today?</summary>\n",
    "\n",
    "- Watch Netflix.\n",
    "- In 100% of past cases where it's a weekday we've watched Netflix!\n",
    "\n",
    "|$Y = $ Activity|$X_1 = $ Day|$X_2 = $ Weather|\n",
    "|:---------:|:--------------:|:----------:|\n",
    "|   Netflix  |      Weekday     |   Sunny  |\n",
    "|   Netflix  |      Weekday     |   Rainy  |\n",
    "|   Netflix  |      Weekday     |   Rainy  |\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>It's a weekend. Based on our past behavior, what do you think we'll do?</summary>\n",
    "\n",
    "- Either go to the movies or go to the beach... but we can't say with certainty whether we'd go to the beach or go to the movies.\n",
    "- Based on our past behavior, we go to the movies on 1/3 of weekend days and we go to the beach on 2/3 of weekend days. (You can think of `.predictproba()`)\n",
    "- If I **had** to make a guess here, I'd probably predict that we would go to the beach, but we may want to use additional information to be certain.\n",
    "\n",
    "|$Y = $ Activity|$X_1 = $ Day|$X_2 = $ Weather|\n",
    "|:---------:|:--------------:|:----------:|\n",
    "|  Movies |      Weekend     |   Rainy  |\n",
    "|  Beach  |      Weekend     |   Sunny  |\n",
    "|  Beach  |      Weekend     |   Sunny  |\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>It's the weekend and the weather is sunny! Based on our past behavior, what do you think we'll do?</summary>\n",
    "\n",
    "- Go to the beach.\n",
    "- In 100% of past cases where the weather is sunny and where it's a weekend, we've gone to the beach.\n",
    "\n",
    "|$Y = $ Activity|$X_1 = $ Day|$X_2 = $ Weather|\n",
    "|:---------:|:--------------:|:----------:|\n",
    "|  Beach  |      Weekend     |   Sunny  |\n",
    "|  Beach  |      Weekend     |   Sunny  |\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees: Overview\n",
    "\n",
    "A decision tree:\n",
    "- takes a dataset consisting of $X$ and $Y$ data, \n",
    "- finds rules based on our $X$ data that partitions (splits) our data into smaller datasets such that\n",
    "- by the bottom of the tree, the values $Y$ in each \"leaf node\" are as \"pure\" as possible.\n",
    "\n",
    "We frequently see decision trees represented by a graph.\n",
    "\n",
    "<img src=\"./images/decision_tree_1.png\" alt=\"what_to_do\" width=\"750\"/>\n",
    "\n",
    "- (This image was created using [Draw.io](https://www.draw.io/).)\n",
    "\n",
    "### Terminology\n",
    "Decision trees look like upside down trees. \n",
    "- What we see on top is known as the \"root node,\" through which all of our observations are passed.\n",
    "- At each internal split, our dataset is partitioned.\n",
    "- A \"parent\" node is split into two or more \"child\" nodes.\n",
    "- At each of the \"leaf nodes\" (colored blue), we contain a subset of records that are as pure as possible.\n",
    "    - In the example above, each leaf node is perfectly pure. Once we get to a leaf node, every observation in that leaf node has the exact same value of $Y$!\n",
    "    - There are ways to quantify the idea of \"purity\" here so that we can let our computer do most of the tree-building (model-fitting) process... we'll come back to this later.\n",
    "\n",
    "Decision trees are also called \"**Classification and Regression Trees**,\" sometimes abbreviated \"**CART**.\"\n",
    "- [DecisionTreeClassifier Documentation](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html)\n",
    "- [DecisionTreeRegressor Documentation](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Purity in Decision Trees\n",
    "\n",
    "When quantifying how \"pure\" a node is, we want to see what the distribution of $Y$ is in each node, then summarize this distribution with a number.\n",
    "\n",
    "<img src=\"./images/decision_tree_1.png\" alt=\"what_to_do\" width=\"750\"/>\n",
    "\n",
    "- For continuous $Y$ (i.e. using a decision tree to predict income), the default option is mean squared error.\n",
    "- This is the `criterion = 'mse'` argument in `DecisionTreeRegressor`.    \n",
    "\n",
    "- For discrete $Y$, the default option is the Gini impurity. *(Bonus: This is not quite the same thing as the [Gini coefficient](https://en.wikipedia.org/wiki/Gini_coefficient).)*\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray*}\n",
    "\\text{Gini impurity} &=& 1 - \\sum_{i=1}^{classes} P(\\text{class i})^2 \\\\\n",
    "\\text{Gini impurity (2 classes)} &=& 1 - P(\\text{class 1})^2 - P(\\text{class 2})^2 \\\\\n",
    "\\text{Gini impurity (3 classes)} &=& 1 - P(\\text{class 1})^2 - P(\\text{class 2})^2 - P(\\text{class 3})^2 \\\\\n",
    "\\end{eqnarray*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our y variable from our \"what should we do\" dataframe.\n",
    "y = ['Movies', 'Netflix', 'Beach', 'Netflix', 'Netflix', 'Beach']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Gini function, called gini.\n",
    "def gini(obs):\n",
    "        \n",
    "    # Create a list to store my squared class probabilities.\n",
    "    probab_sum = []\n",
    "    \n",
    "    # Iterate through each class.\n",
    "        \n",
    "        # Calculate what is the observed probability or frequency of each class (i).\n",
    "        prob = obs.count(observation_i) / len(obs)\n",
    "#         print(f'probability of {observation_i} is {prob}')\n",
    "        \n",
    "        # Square the probability and append it to probab_sum.\n",
    "        probab_sum.append(prob ** 2)\n",
    "#         print(f' the probability sums squarred are {probab_sum}')\n",
    "    \n",
    "    return 1 - sum(probab_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check to see if your Gini function is correct on the \n",
    "# \"what should we do tonight?\" data. (Should get 0.6111.)\n",
    "gini(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gini Practice\n",
    "\n",
    "<details><summary>What is the Gini impurity of a node when every item is from the same class?</summary>\n",
    "    \n",
    "- Our Gini impurity is zero.\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray*}\n",
    "\\text{Gini impurity} &=& 1 - \\sum_{i=1}^{classes} P(\\text{class i})^2 \\\\\n",
    "&=& 1 - P(\\text{class 1})^2 \\\\\n",
    "&=& 1 - 1^2 \\\\\n",
    "&=& 1 - 1 \\\\\n",
    "&=& 0\n",
    "\\end{eqnarray*}\n",
    "$$\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is Gini when every item is from the same class?\n",
    "gini(['Netflix', 'Netflix', 'Netflix'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>What is the Gini impurity of a node when we have two classes, one with two items and the other with one item?</summary>\n",
    "    \n",
    "- Our Gini impurity is 0.5.\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray*}\n",
    "\\text{Gini impurity} &=& 1 - \\sum_{i=1}^{classes} P(\\text{class i})^2 \\\\\n",
    "&=& 1 - P(\\text{class 1})^2 - P(\\text{class 2})^2 \\\\\n",
    "&=& 1 - \\left(\\frac{1}{2}\\right)^2 - \\left(\\frac{1}{2}\\right)^2 \\\\\n",
    "&=& 1 - \\frac{1}{4} - \\frac{1}{4} \\\\\n",
    "&=& \\frac{1}{2}\n",
    "\\end{eqnarray*}\n",
    "$$\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# What is Gini when we have two classes, one with two items and the other with one item?\n",
    "gini(['Movie', 'Beach', 'Beach'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>What is the Gini impurity of a node when we have three classes, each with two items?</summary>\n",
    "    \n",
    "- Our Gini impurity is 0.6667.\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray*}\n",
    "\\text{Gini impurity} &=& 1 - \\sum_{i=1}^{classes} P(\\text{class i})^2 \\\\\n",
    "&=& 1 - P(\\text{class 1})^2 - P(\\text{class 2})^2 - P(\\text{class 3})^2 \\\\\n",
    "&=& 1 - \\left(\\frac{1}{3}\\right)^2 - \\left(\\frac{1}{3}\\right)^2 - \\left(\\frac{1}{3}\\right)^2 \\\\\n",
    "&=& 1 - \\frac{1}{9} - \\frac{1}{9} - \\frac{1}{9} \\\\\n",
    "&=& 1 - \\frac{1}{3} \\\\\n",
    "&=& \\frac{2}{3}\n",
    "\\end{eqnarray*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is Gini when we have three classes, each with two items?\n",
    "gini(['Netflix', 'Netflix', 'Beach', 'Beach', 'Movies', 'Movies'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Summary of Gini Impurity Scores</summary>\n",
    "\n",
    "- In the binary case, Gini impurity ranges from 0 to 0.5.\n",
    "- If we have three classes, Gini impurity ranges from 0 to 0.66667.\n",
    "- If we have $k$ classes, Gini impurity ranges from 0 to $1-\\frac{1}{k}$.\n",
    "- In all cases, a Gini impurity of 0 means maximum purity - all of our observations are from the same class!\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So how does a decision tree use Gini to decide which variable to split on?\n",
    "\n",
    "- At any node, consider the subset of our dataframe that exists at that node.\n",
    "- Iterate through each variable that could potentially split the data.\n",
    "- Calculate the Gini impurity for every possible split.\n",
    "- Select the variable that causes the greatest decrease in Gini impurity from the parent node to the child node.\n",
    "\n",
    "<details><summary>What is the decrease in Gini impurity if we split on $X_1$? (Weekend vs. Weekday)</summary>\n",
    "\n",
    "- Answer: 0.389\n",
    "\n",
    "<img src=\"./images/gini_decrease_4.png\" alt=\"gini_decrease\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>What is the decrease in Gini impurity if we instead split on $X_2$ first? (Sunny Day vs. Rainy Day)</summary>\n",
    "    \n",
    "- Answer: 0.167\n",
    "\n",
    "<img src=\"./images/gini_decrease_3.png\" alt=\"gini_decrease\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One consequence of this is that a decision tree is fit using a **greedy** algorithm. Simply put, a decision tree makes the best short-term decision by optimizing at each node individually. _This might mean that our tree isn't optimal in the long run!_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data.\n",
    "import pandas as pd\n",
    "\n",
    "# Read in Titanic data.\n",
    "titanic = pd.read_csv('./titanic_clean.csv')\n",
    "\n",
    "# Change sex to float.\n",
    "titanic['Sex'] = titanic['Sex'].map({'male':0,\n",
    "                                     'female':1})\n",
    "\n",
    "# Create embarked_S column.\n",
    "titanic['Embarked_s'] = titanic['Embarked'].map({'S':1,\n",
    "                                                 'C':0,\n",
    "                                                 'Q':0})\n",
    "\n",
    "# Create embarked_C column.\n",
    "titanic['Embarked_c'] = titanic['Embarked'].map({'S':0,\n",
    "                                                 'C':1,\n",
    "                                                 'Q':0})\n",
    "\n",
    "# Conduct train/test split.\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(titanic.drop(['Survived','PassengerId','Name','Embarked'], axis=1),\n",
    "                                                    titanic['Survived'],\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check out first five rows of X_train.\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import model.\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>What conclusion would you make here?</summary>\n",
    "\n",
    "- Our model is **very** overfit to the data.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When fitting a decision tree, your model will always grow until it nearly perfectly predicts every observation!\n",
    "- This is like playing a game of 20 questions, but instead calling it \"Infinite Questions.\" You're always going to be able to win!\n",
    "\n",
    "<details><summary>Intuitively, what might you try to do to solve this problem?</summary>\n",
    "    \n",
    "- As with all models, try to gather more data.\n",
    "- As with all models, remove some features.\n",
    "- Is there a way for us to stop our model from growing? (Yes!)\n",
    "</details>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "widgets": {
   "state": {
    "0b28c6b3b13649718658d43e965c8062": {
     "views": [
      {
       "cell_index": 15
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
